---
permalink: /roadmap/

title: "Roadmap"

sidebar:
  nav: "docs"
---

# Robotics Academy - Improve Deep learning Exercise


## Goals

*Custom train or find an enhanced DL model trained to detect only humans specifically. Changes to the pre-processing and post-processing part would have to be made as per the input and output structure of the new model.
*Enhancing the model benchmarking part in terms of its interpretability, use case, accuracy, and visual appeal to the user.
*Enabling GPU support while executing the exercise from the docker container.
*Fluent exercise execution.
*Building a tutorial for the exercise using the Keras Framework, which uses Theano and Tensorflow frameworks as backend.



### References

[1] [https://github.com/JdeRobot/RoboticsAcademy](https://github.com/JdeRobot/RoboticsAcademy)\\
[2] [https://github.com/JdeRobot/DeepLearningStudio](https://github.com/JdeRobot/DeepLearningStudio) \\
[3] [https://developer.nvidia.com/tensorrt](https://developer.nvidia.com/tensorrt) \\
[4] [https://www.tensorflow.org/api_docs/python/tf/quantization/quantize](https://www.tensorflow.org/api_docs/python/tf/quantization/quantize) \\
[5] [https://www.tensorflow.org/model_optimization/guide/pruning](https://www.tensorflow.org/model_optimization/guide/pruning) \\
[6] MobileNetV2: Inverted Residuals and Linear Bottlenecks.‚Äù 2018 [https://arxiv.org/abs/1801.04381](https://arxiv.org/abs/1801.04381) \\
[7] Deep Compression: Compressing Deep Neural Networks with Pruning, Trained Quantization and Huffman Coding [https://arxiv.org/abs/1510.00149](https://arxiv.org/abs/1510.00149) \\
[8] Knowledge Distillation [https://intellabs.github.io/distiller/knowledge_distillation.html](https://intellabs.github.io/distiller/knowledge_distillation.html)